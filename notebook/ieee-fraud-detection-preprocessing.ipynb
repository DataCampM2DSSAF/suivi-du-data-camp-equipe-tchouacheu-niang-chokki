{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\" style=\"color:#6699ff\"> DataCamp IEEE Fraud Detection </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/DataCampM2DSSAF/suivi-du-data-camp-equipe-tchouacheu-niang-chokki/blob/master/img/credit-card-fraud-detection.png?raw=true\" width=\"800\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <a style=\"color:#6699ff\"> Team </a>\n",
    "- <a style=\"color:#6699ff\">Mohamed NIANG </a>\n",
    "- <a style=\"color:#6699ff\">Fernanda Tchouacheu </a>\n",
    "- <a style=\"color:#6699ff\">Hypolite Chokki </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a style=\"color:#6699ff\">  Table of Contents</a> \n",
    "\n",
    "<a style=\"color:#6699ff\"> I. Introduction</a>\n",
    "\n",
    "<a style=\"color:#6699ff\"> II. Descriptive Statistics & Visualization</a>\n",
    "\n",
    "<a style=\"color:#6699ff\"> III. Preprocessing</a>\n",
    "\n",
    "<a style=\"color:#6699ff\"> IV. Machine Learning Models</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a style=\"color:#6699ff\"> I. Introduction</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pourquoi la détection de fraude ?**\n",
    "> La fraude est un commerce d'un milliard de dollars et elle augmente chaque année. L'enquête mondiale de PwC sur la criminalité économique de 2018 a révélé que la moitié (49 %) des 7 200 entreprises interrogées avaient été victimes d'une fraude quelconque. C'est une augmentation par rapport à l'étude PwC de 2016, dans laquelle un peu plus d'un tiers des organisations interrogées (36 %) avaient été victimes de la criminalité économique.\n",
    "\n",
    "\n",
    "Cette compétition est un problème de **classification binaire** - c'est-à-dire que notre variable cible est un attribut binaire (l'utilisateur qui fait le clic est-il frauduleux ou non ?) et notre objectif est de classer les utilisateurs en \"frauduleux\" ou \"non frauduleux\" le mieux possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_identity.csv', 'train_identity.csv', 'test_transaction.csv', 'sample_submission.csv', 'train_transaction.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "import os\n",
    "os.chdir('/kaggle/input/ieeecis-fraud-detection') # Set working directory\n",
    "print(os.listdir('/kaggle/input/ieeecis-fraud-detection'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is loaded!\n",
      "CPU times: user 50.8 s, sys: 3.36 s, total: 54.1 s\n",
      "Wall time: 54.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_transaction = pd.read_csv('train_transaction.csv', index_col='TransactionID')\n",
    "test_transaction = pd.read_csv('test_transaction.csv', index_col='TransactionID')\n",
    "train_identity = pd.read_csv('train_identity.csv', index_col='TransactionID')\n",
    "test_identity = pd.read_csv('test_identity.csv', index_col='TransactionID')\n",
    "print (\"Data is loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_transaction shape is (590540, 393)\n",
      "test_transaction shape is (506691, 392)\n",
      "train_identity shape is (144233, 40)\n",
      "test_identity shape is (141907, 40)\n"
     ]
    }
   ],
   "source": [
    "print('train_transaction shape is {}'.format(train_transaction.shape))\n",
    "print('test_transaction shape is {}'.format(test_transaction.shape))\n",
    "print('train_identity shape is {}'.format(train_identity.shape))\n",
    "print('test_identity shape is {}'.format(test_identity.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a style=\"color:#6699ff\"> III. Preprocessing</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge transaction & identity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tain:  (590540, 433)\n",
      "CPU times: user 4.32 s, sys: 2.21 s, total: 6.54 s\n",
      "Wall time: 6.55 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_df = pd.merge(train_transaction, train_identity, on = \"TransactionID\", how = \"left\")\n",
    "print(\"Tain: \",train_df.shape)\n",
    "del train_transaction, train_identity\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  (506691, 432)\n",
      "CPU times: user 3.92 s, sys: 2.01 s, total: 5.93 s\n",
      "Wall time: 5.96 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test_df = pd.merge(test_transaction, test_identity, on = \"TransactionID\", how = \"left\")\n",
    "print(\"Test: \",test_df.shape)\n",
    "test_df[\"isFraud\"] = 0\n",
    "del test_transaction, test_identity\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline of preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = {\n",
    "'gmail': 'google', \n",
    "'att.net': 'att', \n",
    "'twc.com': 'spectrum', \n",
    "'scranton.edu': 'other', \n",
    "'optonline.net': 'other', \n",
    "'hotmail.co.uk': 'microsoft',\n",
    "'comcast.net': 'other', \n",
    "'yahoo.com.mx': 'yahoo', \n",
    "'yahoo.fr': 'yahoo',\n",
    "'yahoo.es': 'yahoo', \n",
    "'charter.net': 'spectrum', \n",
    "'live.com': 'microsoft', \n",
    "'aim.com': 'aol', \n",
    "'hotmail.de': 'microsoft', \n",
    "'centurylink.net': 'centurylink',\n",
    "'gmail.com': 'google', \n",
    "'me.com': 'apple', \n",
    "'earthlink.net': 'other', \n",
    "'gmx.de': 'other',\n",
    "'web.de': 'other', \n",
    "'cfl.rr.com': 'other', \n",
    "'hotmail.com': 'microsoft', \n",
    "'protonmail.com': 'other', \n",
    "'hotmail.fr': 'microsoft', \n",
    "'windstream.net': 'other', \n",
    "'outlook.es': 'microsoft', \n",
    "'yahoo.co.jp': 'yahoo', \n",
    "'yahoo.de': 'yahoo',\n",
    "'servicios-ta.com': 'other', \n",
    "'netzero.net': 'other', \n",
    "'suddenlink.net': 'other',\n",
    "'roadrunner.com': 'other', \n",
    "'sc.rr.com': 'other', \n",
    "'live.fr': 'microsoft',\n",
    "'verizon.net': 'yahoo', \n",
    "'msn.com': 'microsoft', \n",
    "'q.com': 'centurylink', \n",
    "'prodigy.net.mx': 'att', \n",
    "'frontier.com': 'yahoo', \n",
    "'anonymous.com': 'other', \n",
    "'rocketmail.com': 'yahoo',\n",
    "'sbcglobal.net': 'att',\n",
    "'frontiernet.net': 'yahoo', \n",
    "'ymail.com': 'yahoo',\n",
    "'outlook.com': 'microsoft',\n",
    "'mail.com': 'other', \n",
    "'bellsouth.net': 'other',\n",
    "'embarqmail.com': 'centurylink',\n",
    "'cableone.net': 'other', \n",
    "'hotmail.es': 'microsoft', \n",
    "'mac.com': 'apple',\n",
    "'yahoo.co.uk': 'yahoo',\n",
    "'netzero.com': 'other', \n",
    "'yahoo.com': 'yahoo', \n",
    "'live.com.mx': 'microsoft',\n",
    "'ptd.net': 'other',\n",
    "'cox.net': 'other',\n",
    "'aol.com': 'aol',\n",
    "'juno.com': 'other',\n",
    "'icloud.com': 'apple'\n",
    "}\n",
    "\n",
    "# number types for filtering the columns\n",
    "int_types = [\"int8\", \"int16\", \"int32\", \"int64\", \"float\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check how many missing values has each column.\n",
    "\n",
    "def check_nan(df, limit):\n",
    "    '''\n",
    "    Check how many values are missing in each column.\n",
    "    If the number of missing values are higher than limit, we drop the column.\n",
    "    '''\n",
    "    \n",
    "    total_rows = df.shape[0]\n",
    "    total_cols = df.shape[1]\n",
    "    \n",
    "    total_dropped = 0\n",
    "    col_to_drop = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "\n",
    "        null_sum = df[col].isnull().sum()\n",
    "        perc_over_total = round((null_sum/total_rows), 2)\n",
    "        \n",
    "        if perc_over_total > limit:\n",
    "            \n",
    "            print(\"The col {} contains {} null values.\\nThis represents {} of total rows.\"\\\n",
    "                  .format(col, null_sum, perc_over_total))\n",
    "            \n",
    "            print(\"Dropping column {} from the df.\\n\".format(col))\n",
    "            \n",
    "            col_to_drop.append(col)\n",
    "            total_dropped += 1            \n",
    "    \n",
    "    df.drop(col_to_drop, axis = 1, inplace = True)\n",
    "    print(\"We have dropped a total of {} columns.\\nIt's {} of the total\"\\\n",
    "          .format(total_dropped, round((total_dropped/total_cols), 2)))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarizer(df_train, df_test):\n",
    "    '''\n",
    "    Work with cat features and binarize the values.\n",
    "    Works with 2 dataframes at a time and returns a tupple of both.\n",
    "    '''\n",
    "    cat_cols = df_train.select_dtypes(exclude=int_types).columns\n",
    "\n",
    "    for col in cat_cols:\n",
    "        \n",
    "        # creating a list of unique features to binarize so we dont get and value error\n",
    "        unique_train = list(df_train[col].unique())\n",
    "        unique_test = list(df_test[col].unique())\n",
    "        unique_values = list(set(unique_train + unique_test))\n",
    "        \n",
    "        enc = LabelEncoder()\n",
    "        enc.fit(unique_values)\n",
    "        \n",
    "        df_train[col] = enc.transform((df_train[col].values).reshape(-1 ,1))\n",
    "        df_test[col] = enc.transform((df_test[col].values).reshape(-1 ,1))\n",
    "    \n",
    "    return (df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cathegorical_imputer(df_train, df_test, strategy, fill_value):\n",
    "    '''\n",
    "    Replace all cathegorical features with a constant or the most frequent strategy.\n",
    "    '''\n",
    "    cat_cols = df_train.select_dtypes(exclude=int_types).columns\n",
    "    \n",
    "    for col in cat_cols:\n",
    "        print(\"Working with column {}\".format(col))\n",
    "        \n",
    "        # select the correct inputer\n",
    "        if strategy == \"constant\":\n",
    "            # input a fill_value of -999 to all nulls\n",
    "            inputer = SimpleImputer(strategy=strategy, fill_value=fill_value)\n",
    "        elif strategy == \"most_frequent\":\n",
    "            inputer = SimpleImputer(strategy=strategy)\n",
    "        \n",
    "        # replace the nulls in train and test\n",
    "        df_train[col] = inputer.fit_transform(X = (df_train[col].values).reshape(-1, 1))\n",
    "        df_test[col] = inputer.transform(X = (df_test[col].values).reshape(-1, 1))\n",
    "        \n",
    "    return (df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_inputer(df_train, df_test, strategy, fill_value):\n",
    "    '''\n",
    "    Replace NaN in the numerical features.\n",
    "    Works with 2 dataframes at a time (train & test).\n",
    "    Return a tupple of both.\n",
    "    '''\n",
    "    \n",
    "    # assert valid strategy\n",
    "    message = \"Please select a valid strategy (mean, median, constant (and give a fill_value) or most_frequent)\"\n",
    "    assert strategy in [\"constant\", \"most_frequent\", \"mean\", \"median\"], message\n",
    "    \n",
    "    # int_types defined earlier in the kernel\n",
    "    num_cols = df_train.select_dtypes(include = int_types).columns\n",
    "    \n",
    "    for col in num_cols:\n",
    "\n",
    "        print(\"Working with column {}\".format(col))\n",
    "\n",
    "        # select the correct inputer\n",
    "        if strategy == \"constant\":\n",
    "            inputer = SimpleImputer(strategy=strategy, fill_value=fill_value)\n",
    "        elif strategy == \"most_frequent\":\n",
    "            inputer = SimpleImputer(strategy=strategy)\n",
    "        elif strategy == \"mean\":\n",
    "            inputer = SimpleImputer(strategy=strategy)\n",
    "        elif strategy == \"median\":\n",
    "            inputer = SimpleImputer(strategy=strategy)\n",
    "\n",
    "        # replace the nulls in train and test\n",
    "        try:\n",
    "            df_train[col] = inputer.fit_transform(X = (df_train[col].values).reshape(-1, 1))\n",
    "            df_test[col] = inputer.transform(X = (df_test[col].values).reshape(-1, 1))\n",
    "        except:\n",
    "            print(\"Col {} gave and error.\".format(col))\n",
    "            \n",
    "    return (df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(df_train, df_test):\n",
    "    '''\n",
    "    We define a personal pipeline to process the data and fill with processing functions.\n",
    "    NOTE: modifies the df in place.\n",
    "    '''\n",
    "    print(\"Shape of train is {}\".format(df_train.shape))\n",
    "    print(\"Shape of test is {}\".format(df_test.shape))\n",
    "    # We have set the limit of 70%. If a column contains more that 70% of it's values as NaN/Missing values we will drop the column\n",
    "    # Since it's very unlikely that it will help our future model.\n",
    "    print(\"Checking for nan values\\n\")\n",
    "    df_train = check_nan(df_train, limit=0.7)\n",
    "    \n",
    "    # Select the columns from df_train with less nulls and asign to test.\n",
    "    df_test = df_test[list(df_train.columns)]\n",
    "          \n",
    "    print(\"Shape of train is {}\".format(df_train.shape))\n",
    "    print(\"Shape of test is {}\".format(df_test.shape))\n",
    "          \n",
    "    # mapping emails\n",
    "    print(\"Mapping emails \\n\")\n",
    "    df_train[\"EMAILP\"] = df_train[\"P_emaildomain\"].map(emails)\n",
    "    df_test[\"EMAILP\"] = df_test[\"P_emaildomain\"].map(emails)\n",
    "\n",
    "    print(\"Shape of train is {}\".format(df_train.shape))\n",
    "    print(\"Shape of test is {}\".format(df_test.shape))\n",
    "          \n",
    "    # replace nulls from the train and test df with a value of \"Other\"\n",
    "    print(\"Working with cathegorical values\\n\")\n",
    "    df_train, df_test = cathegorical_imputer(df_train, df_test, strategy = \"constant\", fill_value = \"Other\")\n",
    "    \n",
    "    print(\"Shape of train is {}\".format(df_train.shape))\n",
    "    print(\"Shape of test is {}\".format(df_test.shape))\n",
    "          \n",
    "    # now we will make a one hot encoder of these colums\n",
    "    print(\"Binarazing values\\n\")\n",
    "    df_train, df_test = binarizer(df_train, df_test)\n",
    "    \n",
    "    print(\"Shape of train is {}\".format(df_train.shape))\n",
    "    print(\"Shape of test is {}\".format(df_test.shape))\n",
    "          \n",
    "    # working with null values in numeric columns\n",
    "    print(\"Working with numerical columns. NAN values\\n\")\n",
    "    df_train, df_test = numerical_inputer(df_train, df_test, strategy = \"constant\", fill_value=-999)\n",
    "        \n",
    "    print(\"Shape of train is {}\".format(df_train.shape))\n",
    "    print(\"Shape of test is {}\".format(df_test.shape))\n",
    "          \n",
    "    return (df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train before preprocesing:  (590540, 433)\n",
      "Test before preprocesing:  (506691, 433)\n",
      "Shape of train is (590540, 433)\n",
      "Shape of test is (506691, 433)\n",
      "Checking for nan values\n",
      "\n",
      "The col dist2 contains 552913 null values.\n",
      "This represents 0.94 of total rows.\n",
      "Dropping column dist2 from the df.\n",
      "\n",
      "The col R_emaildomain contains 453249 null values.\n",
      "This represents 0.77 of total rows.\n",
      "Dropping column R_emaildomain from the df.\n",
      "\n",
      "The col D6 contains 517353 null values.\n",
      "This represents 0.88 of total rows.\n",
      "Dropping column D6 from the df.\n",
      "\n",
      "The col D7 contains 551623 null values.\n",
      "This represents 0.93 of total rows.\n",
      "Dropping column D7 from the df.\n",
      "\n",
      "The col D8 contains 515614 null values.\n",
      "This represents 0.87 of total rows.\n",
      "Dropping column D8 from the df.\n",
      "\n",
      "The col D9 contains 515614 null values.\n",
      "This represents 0.87 of total rows.\n",
      "Dropping column D9 from the df.\n",
      "\n",
      "The col D12 contains 525823 null values.\n",
      "This represents 0.89 of total rows.\n",
      "Dropping column D12 from the df.\n",
      "\n",
      "The col D13 contains 528588 null values.\n",
      "This represents 0.9 of total rows.\n",
      "Dropping column D13 from the df.\n",
      "\n",
      "The col D14 contains 528353 null values.\n",
      "This represents 0.89 of total rows.\n",
      "Dropping column D14 from the df.\n",
      "\n",
      "The col V138 contains 508595 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V138 from the df.\n",
      "\n",
      "The col V139 contains 508595 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V139 from the df.\n",
      "\n",
      "The col V140 contains 508595 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V140 from the df.\n",
      "\n",
      "The col V141 contains 508595 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V141 from the df.\n",
      "\n",
      "The col V142 contains 508595 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V142 from the df.\n",
      "\n",
      "The col V143 contains 508589 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V143 from the df.\n",
      "\n",
      "The col V144 contains 508589 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V144 from the df.\n",
      "\n",
      "The col V145 contains 508589 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V145 from the df.\n",
      "\n",
      "The col V146 contains 508595 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V146 from the df.\n",
      "\n",
      "The col V147 contains 508595 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V147 from the df.\n",
      "\n",
      "The col V148 contains 508595 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V148 from the df.\n",
      "\n",
      "The col V149 contains 508595 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V149 from the df.\n",
      "\n",
      "The col V150 contains 508589 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V150 from the df.\n",
      "\n",
      "The col V151 contains 508589 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V151 from the df.\n",
      "\n",
      "The col V152 contains 508589 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V152 from the df.\n",
      "\n",
      "The col V153 contains 508595 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V153 from the df.\n",
      "\n",
      "The col V154 contains 508595 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V154 from the df.\n",
      "\n",
      "The col V155 contains 508595 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V155 from the df.\n",
      "\n",
      "The col V156 contains 508595 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V156 from the df.\n",
      "\n",
      "The col V157 contains 508595 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V157 from the df.\n",
      "\n",
      "The col V158 contains 508595 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V158 from the df.\n",
      "\n",
      "The col V159 contains 508589 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V159 from the df.\n",
      "\n",
      "The col V160 contains 508589 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V160 from the df.\n",
      "\n",
      "The col V161 contains 508595 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V161 from the df.\n",
      "\n",
      "The col V162 contains 508595 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V162 from the df.\n",
      "\n",
      "The col V163 contains 508595 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V163 from the df.\n",
      "\n",
      "The col V164 contains 508589 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V164 from the df.\n",
      "\n",
      "The col V165 contains 508589 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V165 from the df.\n",
      "\n",
      "The col V166 contains 508589 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V166 from the df.\n",
      "\n",
      "The col V167 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V167 from the df.\n",
      "\n",
      "The col V168 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V168 from the df.\n",
      "\n",
      "The col V169 contains 450721 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V169 from the df.\n",
      "\n",
      "The col V170 contains 450721 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V170 from the df.\n",
      "\n",
      "The col V171 contains 450721 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V171 from the df.\n",
      "\n",
      "The col V172 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V172 from the df.\n",
      "\n",
      "The col V173 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V173 from the df.\n",
      "\n",
      "The col V174 contains 450721 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V174 from the df.\n",
      "\n",
      "The col V175 contains 450721 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V175 from the df.\n",
      "\n",
      "The col V176 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V176 from the df.\n",
      "\n",
      "The col V177 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V177 from the df.\n",
      "\n",
      "The col V178 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V178 from the df.\n",
      "\n",
      "The col V179 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V179 from the df.\n",
      "\n",
      "The col V180 contains 450721 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V180 from the df.\n",
      "\n",
      "The col V181 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V181 from the df.\n",
      "\n",
      "The col V182 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V182 from the df.\n",
      "\n",
      "The col V183 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V183 from the df.\n",
      "\n",
      "The col V184 contains 450721 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V184 from the df.\n",
      "\n",
      "The col V185 contains 450721 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V185 from the df.\n",
      "\n",
      "The col V186 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V186 from the df.\n",
      "\n",
      "The col V187 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V187 from the df.\n",
      "\n",
      "The col V188 contains 450721 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V188 from the df.\n",
      "\n",
      "The col V189 contains 450721 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V189 from the df.\n",
      "\n",
      "The col V190 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V190 from the df.\n",
      "\n",
      "The col V191 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V191 from the df.\n",
      "\n",
      "The col V192 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V192 from the df.\n",
      "\n",
      "The col V193 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V193 from the df.\n",
      "\n",
      "The col V194 contains 450721 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V194 from the df.\n",
      "\n",
      "The col V195 contains 450721 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V195 from the df.\n",
      "\n",
      "The col V196 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V196 from the df.\n",
      "\n",
      "The col V197 contains 450721 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V197 from the df.\n",
      "\n",
      "The col V198 contains 450721 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V198 from the df.\n",
      "\n",
      "The col V199 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V199 from the df.\n",
      "\n",
      "The col V200 contains 450721 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V200 from the df.\n",
      "\n",
      "The col V201 contains 450721 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V201 from the df.\n",
      "\n",
      "The col V202 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V202 from the df.\n",
      "\n",
      "The col V203 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V203 from the df.\n",
      "\n",
      "The col V204 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V204 from the df.\n",
      "\n",
      "The col V205 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V205 from the df.\n",
      "\n",
      "The col V206 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V206 from the df.\n",
      "\n",
      "The col V207 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V207 from the df.\n",
      "\n",
      "The col V208 contains 450721 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V208 from the df.\n",
      "\n",
      "The col V209 contains 450721 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V209 from the df.\n",
      "\n",
      "The col V210 contains 450721 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V210 from the df.\n",
      "\n",
      "The col V211 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V211 from the df.\n",
      "\n",
      "The col V212 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V212 from the df.\n",
      "\n",
      "The col V213 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V213 from the df.\n",
      "\n",
      "The col V214 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V214 from the df.\n",
      "\n",
      "The col V215 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V215 from the df.\n",
      "\n",
      "The col V216 contains 450909 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V216 from the df.\n",
      "\n",
      "The col V217 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V217 from the df.\n",
      "\n",
      "The col V218 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V218 from the df.\n",
      "\n",
      "The col V219 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V219 from the df.\n",
      "\n",
      "The col V220 contains 449124 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V220 from the df.\n",
      "\n",
      "The col V221 contains 449124 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V221 from the df.\n",
      "\n",
      "The col V222 contains 449124 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V222 from the df.\n",
      "\n",
      "The col V223 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V223 from the df.\n",
      "\n",
      "The col V224 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V224 from the df.\n",
      "\n",
      "The col V225 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V225 from the df.\n",
      "\n",
      "The col V226 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V226 from the df.\n",
      "\n",
      "The col V227 contains 449124 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V227 from the df.\n",
      "\n",
      "The col V228 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V228 from the df.\n",
      "\n",
      "The col V229 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V229 from the df.\n",
      "\n",
      "The col V230 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V230 from the df.\n",
      "\n",
      "The col V231 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V231 from the df.\n",
      "\n",
      "The col V232 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V232 from the df.\n",
      "\n",
      "The col V233 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V233 from the df.\n",
      "\n",
      "The col V234 contains 449124 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V234 from the df.\n",
      "\n",
      "The col V235 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V235 from the df.\n",
      "\n",
      "The col V236 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V236 from the df.\n",
      "\n",
      "The col V237 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V237 from the df.\n",
      "\n",
      "The col V238 contains 449124 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V238 from the df.\n",
      "\n",
      "The col V239 contains 449124 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V239 from the df.\n",
      "\n",
      "The col V240 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V240 from the df.\n",
      "\n",
      "The col V241 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V241 from the df.\n",
      "\n",
      "The col V242 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V242 from the df.\n",
      "\n",
      "The col V243 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V243 from the df.\n",
      "\n",
      "The col V244 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V244 from the df.\n",
      "\n",
      "The col V245 contains 449124 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V245 from the df.\n",
      "\n",
      "The col V246 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V246 from the df.\n",
      "\n",
      "The col V247 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V247 from the df.\n",
      "\n",
      "The col V248 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V248 from the df.\n",
      "\n",
      "The col V249 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V249 from the df.\n",
      "\n",
      "The col V250 contains 449124 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V250 from the df.\n",
      "\n",
      "The col V251 contains 449124 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V251 from the df.\n",
      "\n",
      "The col V252 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V252 from the df.\n",
      "\n",
      "The col V253 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V253 from the df.\n",
      "\n",
      "The col V254 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V254 from the df.\n",
      "\n",
      "The col V255 contains 449124 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V255 from the df.\n",
      "\n",
      "The col V256 contains 449124 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V256 from the df.\n",
      "\n",
      "The col V257 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V257 from the df.\n",
      "\n",
      "The col V258 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V258 from the df.\n",
      "\n",
      "The col V259 contains 449124 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V259 from the df.\n",
      "\n",
      "The col V260 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V260 from the df.\n",
      "\n",
      "The col V261 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V261 from the df.\n",
      "\n",
      "The col V262 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V262 from the df.\n",
      "\n",
      "The col V263 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V263 from the df.\n",
      "\n",
      "The col V264 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V264 from the df.\n",
      "\n",
      "The col V265 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V265 from the df.\n",
      "\n",
      "The col V266 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V266 from the df.\n",
      "\n",
      "The col V267 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V267 from the df.\n",
      "\n",
      "The col V268 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V268 from the df.\n",
      "\n",
      "The col V269 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V269 from the df.\n",
      "\n",
      "The col V270 contains 449124 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V270 from the df.\n",
      "\n",
      "The col V271 contains 449124 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V271 from the df.\n",
      "\n",
      "The col V272 contains 449124 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column V272 from the df.\n",
      "\n",
      "The col V273 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V273 from the df.\n",
      "\n",
      "The col V274 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V274 from the df.\n",
      "\n",
      "The col V275 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V275 from the df.\n",
      "\n",
      "The col V276 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V276 from the df.\n",
      "\n",
      "The col V277 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V277 from the df.\n",
      "\n",
      "The col V278 contains 460110 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column V278 from the df.\n",
      "\n",
      "The col V322 contains 508189 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V322 from the df.\n",
      "\n",
      "The col V323 contains 508189 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V323 from the df.\n",
      "\n",
      "The col V324 contains 508189 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V324 from the df.\n",
      "\n",
      "The col V325 contains 508189 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V325 from the df.\n",
      "\n",
      "The col V326 contains 508189 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V326 from the df.\n",
      "\n",
      "The col V327 contains 508189 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V327 from the df.\n",
      "\n",
      "The col V328 contains 508189 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V328 from the df.\n",
      "\n",
      "The col V329 contains 508189 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V329 from the df.\n",
      "\n",
      "The col V330 contains 508189 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V330 from the df.\n",
      "\n",
      "The col V331 contains 508189 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V331 from the df.\n",
      "\n",
      "The col V332 contains 508189 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V332 from the df.\n",
      "\n",
      "The col V333 contains 508189 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V333 from the df.\n",
      "\n",
      "The col V334 contains 508189 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V334 from the df.\n",
      "\n",
      "The col V335 contains 508189 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V335 from the df.\n",
      "\n",
      "The col V336 contains 508189 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V336 from the df.\n",
      "\n",
      "The col V337 contains 508189 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V337 from the df.\n",
      "\n",
      "The col V338 contains 508189 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V338 from the df.\n",
      "\n",
      "The col V339 contains 508189 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column V339 from the df.\n",
      "\n",
      "The col id_01 contains 446307 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column id_01 from the df.\n",
      "\n",
      "The col id_02 contains 449668 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column id_02 from the df.\n",
      "\n",
      "The col id_03 contains 524216 null values.\n",
      "This represents 0.89 of total rows.\n",
      "Dropping column id_03 from the df.\n",
      "\n",
      "The col id_04 contains 524216 null values.\n",
      "This represents 0.89 of total rows.\n",
      "Dropping column id_04 from the df.\n",
      "\n",
      "The col id_05 contains 453675 null values.\n",
      "This represents 0.77 of total rows.\n",
      "Dropping column id_05 from the df.\n",
      "\n",
      "The col id_06 contains 453675 null values.\n",
      "This represents 0.77 of total rows.\n",
      "Dropping column id_06 from the df.\n",
      "\n",
      "The col id_07 contains 585385 null values.\n",
      "This represents 0.99 of total rows.\n",
      "Dropping column id_07 from the df.\n",
      "\n",
      "The col id_08 contains 585385 null values.\n",
      "This represents 0.99 of total rows.\n",
      "Dropping column id_08 from the df.\n",
      "\n",
      "The col id_09 contains 515614 null values.\n",
      "This represents 0.87 of total rows.\n",
      "Dropping column id_09 from the df.\n",
      "\n",
      "The col id_10 contains 515614 null values.\n",
      "This represents 0.87 of total rows.\n",
      "Dropping column id_10 from the df.\n",
      "\n",
      "The col id_11 contains 449562 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column id_11 from the df.\n",
      "\n",
      "The col id_12 contains 446307 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column id_12 from the df.\n",
      "\n",
      "The col id_13 contains 463220 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column id_13 from the df.\n",
      "\n",
      "The col id_14 contains 510496 null values.\n",
      "This represents 0.86 of total rows.\n",
      "Dropping column id_14 from the df.\n",
      "\n",
      "The col id_15 contains 449555 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column id_15 from the df.\n",
      "\n",
      "The col id_16 contains 461200 null values.\n",
      "This represents 0.78 of total rows.\n",
      "Dropping column id_16 from the df.\n",
      "\n",
      "The col id_17 contains 451171 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column id_17 from the df.\n",
      "\n",
      "The col id_18 contains 545427 null values.\n",
      "This represents 0.92 of total rows.\n",
      "Dropping column id_18 from the df.\n",
      "\n",
      "The col id_19 contains 451222 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column id_19 from the df.\n",
      "\n",
      "The col id_20 contains 451279 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column id_20 from the df.\n",
      "\n",
      "The col id_21 contains 585381 null values.\n",
      "This represents 0.99 of total rows.\n",
      "Dropping column id_21 from the df.\n",
      "\n",
      "The col id_22 contains 585371 null values.\n",
      "This represents 0.99 of total rows.\n",
      "Dropping column id_22 from the df.\n",
      "\n",
      "The col id_23 contains 585371 null values.\n",
      "This represents 0.99 of total rows.\n",
      "Dropping column id_23 from the df.\n",
      "\n",
      "The col id_24 contains 585793 null values.\n",
      "This represents 0.99 of total rows.\n",
      "Dropping column id_24 from the df.\n",
      "\n",
      "The col id_25 contains 585408 null values.\n",
      "This represents 0.99 of total rows.\n",
      "Dropping column id_25 from the df.\n",
      "\n",
      "The col id_26 contains 585377 null values.\n",
      "This represents 0.99 of total rows.\n",
      "Dropping column id_26 from the df.\n",
      "\n",
      "The col id_27 contains 585371 null values.\n",
      "This represents 0.99 of total rows.\n",
      "Dropping column id_27 from the df.\n",
      "\n",
      "The col id_28 contains 449562 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column id_28 from the df.\n",
      "\n",
      "The col id_29 contains 449562 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column id_29 from the df.\n",
      "\n",
      "The col id_30 contains 512975 null values.\n",
      "This represents 0.87 of total rows.\n",
      "Dropping column id_30 from the df.\n",
      "\n",
      "The col id_31 contains 450258 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column id_31 from the df.\n",
      "\n",
      "The col id_32 contains 512954 null values.\n",
      "This represents 0.87 of total rows.\n",
      "Dropping column id_32 from the df.\n",
      "\n",
      "The col id_33 contains 517251 null values.\n",
      "This represents 0.88 of total rows.\n",
      "Dropping column id_33 from the df.\n",
      "\n",
      "The col id_34 contains 512735 null values.\n",
      "This represents 0.87 of total rows.\n",
      "Dropping column id_34 from the df.\n",
      "\n",
      "The col id_35 contains 449555 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column id_35 from the df.\n",
      "\n",
      "The col id_36 contains 449555 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column id_36 from the df.\n",
      "\n",
      "The col id_37 contains 449555 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column id_37 from the df.\n",
      "\n",
      "The col id_38 contains 449555 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column id_38 from the df.\n",
      "\n",
      "The col DeviceType contains 449730 null values.\n",
      "This represents 0.76 of total rows.\n",
      "Dropping column DeviceType from the df.\n",
      "\n",
      "The col DeviceInfo contains 471874 null values.\n",
      "This represents 0.8 of total rows.\n",
      "Dropping column DeviceInfo from the df.\n",
      "\n",
      "We have dropped a total of 208 columns.\n",
      "It's 0.48 of the total\n",
      "Shape of train is (590540, 225)\n",
      "Shape of test is (506691, 225)\n",
      "Mapping emails \n",
      "\n",
      "Shape of train is (590540, 226)\n",
      "Shape of test is (506691, 226)\n",
      "Working with cathegorical values\n",
      "\n",
      "Working with column ProductCD\n",
      "Working with column card4\n",
      "Working with column card6\n",
      "Working with column P_emaildomain\n",
      "Working with column M1\n",
      "Working with column M2\n",
      "Working with column M3\n",
      "Working with column M4\n",
      "Working with column M5\n",
      "Working with column M6\n",
      "Working with column M7\n",
      "Working with column M8\n",
      "Working with column M9\n",
      "Working with column EMAILP\n",
      "Shape of train is (590540, 226)\n",
      "Shape of test is (506691, 226)\n",
      "Binarazing values\n",
      "\n",
      "Shape of train is (590540, 226)\n",
      "Shape of test is (506691, 226)\n",
      "Working with numerical columns. NAN values\n",
      "\n",
      "Working with column isFraud\n",
      "Working with column TransactionDT\n",
      "Working with column TransactionAmt\n",
      "Working with column ProductCD\n",
      "Working with column card1\n",
      "Working with column card2\n",
      "Working with column card3\n",
      "Working with column card4\n",
      "Working with column card5\n",
      "Working with column card6\n",
      "Working with column addr1\n",
      "Working with column addr2\n",
      "Working with column dist1\n",
      "Working with column P_emaildomain\n",
      "Working with column C1\n",
      "Working with column C2\n",
      "Working with column C3\n",
      "Working with column C4\n",
      "Working with column C5\n",
      "Working with column C6\n",
      "Working with column C7\n",
      "Working with column C8\n",
      "Working with column C9\n",
      "Working with column C10\n",
      "Working with column C11\n",
      "Working with column C12\n",
      "Working with column C13\n",
      "Working with column C14\n",
      "Working with column D1\n",
      "Working with column D2\n",
      "Working with column D3\n",
      "Working with column D4\n",
      "Working with column D5\n",
      "Working with column D10\n",
      "Working with column D11\n",
      "Working with column D15\n",
      "Working with column M1\n",
      "Working with column M2\n",
      "Working with column M3\n",
      "Working with column M4\n",
      "Working with column M5\n",
      "Working with column M6\n",
      "Working with column M7\n",
      "Working with column M8\n",
      "Working with column M9\n",
      "Working with column V1\n",
      "Working with column V2\n",
      "Working with column V3\n",
      "Working with column V4\n",
      "Working with column V5\n",
      "Working with column V6\n",
      "Working with column V7\n",
      "Working with column V8\n",
      "Working with column V9\n",
      "Working with column V10\n",
      "Working with column V11\n",
      "Working with column V12\n",
      "Working with column V13\n",
      "Working with column V14\n",
      "Working with column V15\n",
      "Working with column V16\n",
      "Working with column V17\n",
      "Working with column V18\n",
      "Working with column V19\n",
      "Working with column V20\n",
      "Working with column V21\n",
      "Working with column V22\n",
      "Working with column V23\n",
      "Working with column V24\n",
      "Working with column V25\n",
      "Working with column V26\n",
      "Working with column V27\n",
      "Working with column V28\n",
      "Working with column V29\n",
      "Working with column V30\n",
      "Working with column V31\n",
      "Working with column V32\n",
      "Working with column V33\n",
      "Working with column V34\n",
      "Working with column V35\n",
      "Working with column V36\n",
      "Working with column V37\n",
      "Working with column V38\n",
      "Working with column V39\n",
      "Working with column V40\n",
      "Working with column V41\n",
      "Working with column V42\n",
      "Working with column V43\n",
      "Working with column V44\n",
      "Working with column V45\n",
      "Working with column V46\n",
      "Working with column V47\n",
      "Working with column V48\n",
      "Working with column V49\n",
      "Working with column V50\n",
      "Working with column V51\n",
      "Working with column V52\n",
      "Working with column V53\n",
      "Working with column V54\n",
      "Working with column V55\n",
      "Working with column V56\n",
      "Working with column V57\n",
      "Working with column V58\n",
      "Working with column V59\n",
      "Working with column V60\n",
      "Working with column V61\n",
      "Working with column V62\n",
      "Working with column V63\n",
      "Working with column V64\n",
      "Working with column V65\n",
      "Working with column V66\n",
      "Working with column V67\n",
      "Working with column V68\n",
      "Working with column V69\n",
      "Working with column V70\n",
      "Working with column V71\n",
      "Working with column V72\n",
      "Working with column V73\n",
      "Working with column V74\n",
      "Working with column V75\n",
      "Working with column V76\n",
      "Working with column V77\n",
      "Working with column V78\n",
      "Working with column V79\n",
      "Working with column V80\n",
      "Working with column V81\n",
      "Working with column V82\n",
      "Working with column V83\n",
      "Working with column V84\n",
      "Working with column V85\n",
      "Working with column V86\n",
      "Working with column V87\n",
      "Working with column V88\n",
      "Working with column V89\n",
      "Working with column V90\n",
      "Working with column V91\n",
      "Working with column V92\n",
      "Working with column V93\n",
      "Working with column V94\n",
      "Working with column V95\n",
      "Working with column V96\n",
      "Working with column V97\n",
      "Working with column V98\n",
      "Working with column V99\n",
      "Working with column V100\n",
      "Working with column V101\n",
      "Working with column V102\n",
      "Working with column V103\n",
      "Working with column V104\n",
      "Working with column V105\n",
      "Working with column V106\n",
      "Working with column V107\n",
      "Working with column V108\n",
      "Working with column V109\n",
      "Working with column V110\n",
      "Working with column V111\n",
      "Working with column V112\n",
      "Working with column V113\n",
      "Working with column V114\n",
      "Working with column V115\n",
      "Working with column V116\n",
      "Working with column V117\n",
      "Working with column V118\n",
      "Working with column V119\n",
      "Working with column V120\n",
      "Working with column V121\n",
      "Working with column V122\n",
      "Working with column V123\n",
      "Working with column V124\n",
      "Working with column V125\n",
      "Working with column V126\n",
      "Working with column V127\n",
      "Working with column V128\n",
      "Working with column V129\n",
      "Working with column V130\n",
      "Working with column V131\n",
      "Working with column V132\n",
      "Working with column V133\n",
      "Working with column V134\n",
      "Working with column V135\n",
      "Working with column V136\n",
      "Working with column V137\n",
      "Working with column V279\n",
      "Working with column V280\n",
      "Working with column V281\n",
      "Working with column V282\n",
      "Working with column V283\n",
      "Working with column V284\n",
      "Working with column V285\n",
      "Working with column V286\n",
      "Working with column V287\n",
      "Working with column V288\n",
      "Working with column V289\n",
      "Working with column V290\n",
      "Working with column V291\n",
      "Working with column V292\n",
      "Working with column V293\n",
      "Working with column V294\n",
      "Working with column V295\n",
      "Working with column V296\n",
      "Working with column V297\n",
      "Working with column V298\n",
      "Working with column V299\n",
      "Working with column V300\n",
      "Working with column V301\n",
      "Working with column V302\n",
      "Working with column V303\n",
      "Working with column V304\n",
      "Working with column V305\n",
      "Working with column V306\n",
      "Working with column V307\n",
      "Working with column V308\n",
      "Working with column V309\n",
      "Working with column V310\n",
      "Working with column V311\n",
      "Working with column V312\n",
      "Working with column V313\n",
      "Working with column V314\n",
      "Working with column V315\n",
      "Working with column V316\n",
      "Working with column V317\n",
      "Working with column V318\n",
      "Working with column V319\n",
      "Working with column V320\n",
      "Working with column V321\n",
      "Working with column EMAILP\n",
      "Shape of train is (590540, 226)\n",
      "Shape of test is (506691, 226)\n",
      "Train after preprocesing:  (590540, 226)\n",
      "Test after preprocesing:  (506691, 226)\n"
     ]
    }
   ],
   "source": [
    "# before preprocesing\n",
    "print(\"Train before preprocesing: \",train_df.shape)\n",
    "print(\"Test before preprocesing: \",test_df.shape)\n",
    "\n",
    "train_df, test_df = pipeline(train_df, test_df)\n",
    "\n",
    "# after preprocesing\n",
    "print(\"Train after preprocesing: \",train_df.shape)\n",
    "print(\"Test after preprocesing: \",test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>card6</th>\n",
       "      <th>...</th>\n",
       "      <th>V313</th>\n",
       "      <th>V314</th>\n",
       "      <th>V315</th>\n",
       "      <th>V316</th>\n",
       "      <th>V317</th>\n",
       "      <th>V318</th>\n",
       "      <th>V319</th>\n",
       "      <th>V320</th>\n",
       "      <th>V321</th>\n",
       "      <th>EMAILP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransactionID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2987000</th>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.50</td>\n",
       "      <td>4</td>\n",
       "      <td>13926</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987001</th>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.00</td>\n",
       "      <td>4</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3</td>\n",
       "      <td>102.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987002</th>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.00</td>\n",
       "      <td>4</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4</td>\n",
       "      <td>166.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987003</th>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.00</td>\n",
       "      <td>4</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3</td>\n",
       "      <td>117.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987004</th>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3</td>\n",
       "      <td>102.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577535</th>\n",
       "      <td>0</td>\n",
       "      <td>15811047</td>\n",
       "      <td>49.00</td>\n",
       "      <td>4</td>\n",
       "      <td>6550</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4</td>\n",
       "      <td>226.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>47.950001</td>\n",
       "      <td>47.950001</td>\n",
       "      <td>47.950001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577536</th>\n",
       "      <td>0</td>\n",
       "      <td>15811049</td>\n",
       "      <td>39.50</td>\n",
       "      <td>4</td>\n",
       "      <td>10444</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3</td>\n",
       "      <td>224.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577537</th>\n",
       "      <td>0</td>\n",
       "      <td>15811079</td>\n",
       "      <td>30.95</td>\n",
       "      <td>4</td>\n",
       "      <td>12037</td>\n",
       "      <td>595.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3</td>\n",
       "      <td>224.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577538</th>\n",
       "      <td>0</td>\n",
       "      <td>15811088</td>\n",
       "      <td>117.00</td>\n",
       "      <td>4</td>\n",
       "      <td>7826</td>\n",
       "      <td>481.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3</td>\n",
       "      <td>224.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>317.500000</td>\n",
       "      <td>669.500000</td>\n",
       "      <td>317.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577539</th>\n",
       "      <td>0</td>\n",
       "      <td>15811131</td>\n",
       "      <td>279.95</td>\n",
       "      <td>4</td>\n",
       "      <td>15066</td>\n",
       "      <td>170.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3</td>\n",
       "      <td>102.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>279.950012</td>\n",
       "      <td>279.950012</td>\n",
       "      <td>279.950012</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>590540 rows × 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               isFraud  TransactionDT  TransactionAmt  ProductCD  card1  \\\n",
       "TransactionID                                                             \n",
       "2987000              0          86400           68.50          4  13926   \n",
       "2987001              0          86401           29.00          4   2755   \n",
       "2987002              0          86469           59.00          4   4663   \n",
       "2987003              0          86499           50.00          4  18132   \n",
       "2987004              0          86506           50.00          1   4497   \n",
       "...                ...            ...             ...        ...    ...   \n",
       "3577535              0       15811047           49.00          4   6550   \n",
       "3577536              0       15811049           39.50          4  10444   \n",
       "3577537              0       15811079           30.95          4  12037   \n",
       "3577538              0       15811088          117.00          4   7826   \n",
       "3577539              0       15811131          279.95          4  15066   \n",
       "\n",
       "               card2  card3  card4  card5  card6  ...        V313        V314  \\\n",
       "TransactionID                                     ...                           \n",
       "2987000       -999.0  150.0      2  142.0      2  ...    0.000000    0.000000   \n",
       "2987001        404.0  150.0      3  102.0      2  ...    0.000000    0.000000   \n",
       "2987002        490.0  150.0      4  166.0      3  ...    0.000000    0.000000   \n",
       "2987003        567.0  150.0      3  117.0      3  ...    0.000000    0.000000   \n",
       "2987004        514.0  150.0      3  102.0      2  ...    0.000000    0.000000   \n",
       "...              ...    ...    ...    ...    ...  ...         ...         ...   \n",
       "3577535       -999.0  150.0      4  226.0      3  ...   47.950001   47.950001   \n",
       "3577536        225.0  150.0      3  224.0      3  ...    0.000000    0.000000   \n",
       "3577537        595.0  150.0      3  224.0      3  ...    0.000000    0.000000   \n",
       "3577538        481.0  150.0      3  224.0      3  ...  317.500000  669.500000   \n",
       "3577539        170.0  150.0      3  102.0      2  ...    0.000000    0.000000   \n",
       "\n",
       "                     V315  V316    V317   V318        V319        V320  \\\n",
       "TransactionID                                                            \n",
       "2987000          0.000000   0.0   117.0    0.0    0.000000    0.000000   \n",
       "2987001          0.000000   0.0     0.0    0.0    0.000000    0.000000   \n",
       "2987002          0.000000   0.0     0.0    0.0    0.000000    0.000000   \n",
       "2987003          0.000000  50.0  1404.0  790.0    0.000000    0.000000   \n",
       "2987004          0.000000   0.0     0.0    0.0    0.000000    0.000000   \n",
       "...                   ...   ...     ...    ...         ...         ...   \n",
       "3577535         47.950001   0.0     0.0    0.0    0.000000    0.000000   \n",
       "3577536          0.000000   0.0     0.0    0.0    0.000000    0.000000   \n",
       "3577537          0.000000   0.0     0.0    0.0    0.000000    0.000000   \n",
       "3577538        317.500000   0.0  2234.0    0.0    0.000000    0.000000   \n",
       "3577539          0.000000   0.0     0.0    0.0  279.950012  279.950012   \n",
       "\n",
       "                     V321  EMAILP  \n",
       "TransactionID                      \n",
       "2987000          0.000000       0  \n",
       "2987001          0.000000       5  \n",
       "2987002          0.000000       6  \n",
       "2987003          0.000000       9  \n",
       "2987004          0.000000       5  \n",
       "...                   ...     ...  \n",
       "3577535          0.000000       0  \n",
       "3577536          0.000000       5  \n",
       "3577537          0.000000       5  \n",
       "3577538          0.000000       1  \n",
       "3577539        279.950012       5  \n",
       "\n",
       "[590540 rows x 226 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "columns = train_df.columns\n",
    "for col in  columns:\n",
    "    total_nulls = train_df[col].isnull().sum()\n",
    "    if total_nulls > 0:\n",
    "        print(col, total_nulls)\n",
    "        \n",
    "columns = test_df.select_dtypes(exclude=int_types).columns\n",
    "train_df[columns]\n",
    "\n",
    "columns = test_df.select_dtypes(include=int_types).columns\n",
    "train_df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_pickle('/kaggle/working/train_df.pkl')\n",
    "test_df.to_pickle('/kaggle/working/test_df.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
